{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494a4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07c9ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_reviews(path, n=1000, seed=42):\n",
    "    # 第一次遍历，统计总行数\n",
    "    with open(path, 'rt', encoding='utf-8') as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "\n",
    "    reviews = []\n",
    "    # 第二次遍历，显示进度条\n",
    "    with open(path, 'rt', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, total=total_lines, desc=\"Processing reviews\"):\n",
    "            try:\n",
    "                review = json.loads(line)\n",
    "                if review.get(\"text\") and review[\"text\"].strip():  # 过滤掉空评论\n",
    "                    reviews.append(review)\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # 避免坏行报错\n",
    "\n",
    "    print(f\"总评论数: {len(reviews)}\")\n",
    "\n",
    "    # 固定随机种子，保证结果可复现\n",
    "    random.seed(seed)\n",
    "    sampled = random.sample(reviews, min(n, len(reviews)))\n",
    "    return sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e5a3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing reviews: 100%|██████████| 5011462/5011462 [00:14<00:00, 335848.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总评论数: 2743267\n"
     ]
    }
   ],
   "source": [
    "sampled_reviews = sample_reviews(\"../data/in/review-Oklahoma_10.json\", n=1000)\n",
    "\n",
    "# 转换成 DataFrame 并保存\n",
    "df = pd.DataFrame(sampled_reviews)\n",
    "df[\"review_length\"] = df[\"text\"].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50390f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../in/data/meta-Oklahoma.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m reviews_df = df\n\u001b[32m      2\u001b[39m places_data = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../in/data/meta-Oklahoma.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(f, start=\u001b[32m1\u001b[39m):\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML-for-Trustworthy-Location-Reviews/myenv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../in/data/meta-Oklahoma.json'"
     ]
    }
   ],
   "source": [
    "reviews_df = df\n",
    "places_data = []\n",
    "with open(\"../in/data/meta-Oklahoma.json\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f, start=1):\n",
    "        try:\n",
    "            places_data.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"⚠️ 跳过坏行 {i}\")\n",
    "            continue\n",
    "\n",
    "places_df = pd.DataFrame(places_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认 gmap_id 在两个表里都是字符串\n",
    "reviews_df['gmap_id'] = reviews_df['gmap_id'].astype(str)\n",
    "places_df['gmap_id'] = places_df['gmap_id'].astype(str)\n",
    "\n",
    "# inner join（只保留两个表都有 gmap_id 的）\n",
    "merged_df = reviews_df.merge(\n",
    "    places_df.drop_duplicates(subset=[\"gmap_id\"])\n",
    "    , on=\"gmap_id\", how=\"left\")\n",
    "\n",
    "print(f\"合并后数据量: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81486d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果\n",
    "merged_df.to_csv(\"data/reviews_with_places_1000_Oklahoma.csv\", index=False)\n",
    "print(\"已保存 reviews_with_places_1000_Oklahoma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查 description 列的缺失情况\n",
    "print(\"总行数:\", len(df))\n",
    "print(\"description 缺失数量:\", df['description'].isnull().sum())\n",
    "print(\"description 非缺失数量:\", df['description'].notnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2d529",
   "metadata": {},
   "source": [
    "<h1>清理merge数据</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c614caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/yuanyusi/Desktop/ML-for-Trustworthy-Location-Reviews/src\n",
      "Files in current directory: ['filter_invalid.py', 'merge.py', 'data_clean.py', 'data_clean.ipynb', 'prompt_labelling.ipynb', 'merge_all.ipynb', 'prompt_labelling.py']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files in current directory:\", os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c58afb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean merged data.\n",
    "df = pd.read_csv(\"../data/out/merged_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['name', 'index', 'rating', 'error'])\n",
    "df = df[df['predicted_label'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d69c1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/out/merged_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bdd34",
   "metadata": {},
   "source": [
    "<h1>Concatenate Original & Syn Data (with shuffle) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7d66001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "df1 = pd.read_csv('../data/synthesized_data/syn_ad.csv')\n",
    "df2 = pd.read_csv('../data/synthesized_data/syn_rant.csv')\n",
    "df3 = pd.read_csv('../data/out/merged_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5e72668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate them\n",
    "combined_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Shuffle using pandas sample method\n",
    "shuffled_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save to new file\n",
    "shuffled_df.to_csv('../data/out/combined_shuffled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
