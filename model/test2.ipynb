{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf39d732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "seed=random.randint(0,100)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e983481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_label\n",
       "Valid                 7681\n",
       "Irrelevant             480\n",
       "Advertisement          172\n",
       "Rant_Without_Visit     135\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/out/augmented_shuffled.csv')\n",
    "df = df.dropna(subset=[\"predicted_label\"])\n",
    "df = df[df[\"predicted_label\"].str.strip() != \"\"]\n",
    "df['predicted_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5be61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label\n",
      "Irrelevant            480\n",
      "Valid                 300\n",
      "Advertisement         172\n",
      "Rant_Without_Visit    135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate the DataFrame into 'valid' and 'non-valid' rows.\n",
    "df_valid = df[df['predicted_label'] == 'Valid']\n",
    "df_other = df[df['predicted_label'] != 'Valid']\n",
    "\n",
    "# Randomly sample 300 rows from the 'valid' DataFrame.\n",
    "df_valid_sampled = df_valid.sample(n=300, random_state=seed)\n",
    "\n",
    "# Concatenate the sampled 'valid' rows with the 'non-valid' rows.\n",
    "df = pd.concat([df_valid_sampled, df_other])\n",
    "\n",
    "# Print the value counts of the updated DataFrame.\n",
    "print(df['predicted_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91653580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmapped labels: 0\n"
     ]
    }
   ],
   "source": [
    "tag_mapping_dict = {\n",
    "    'Valid': 0,\n",
    "    'Advertisement': 1,\n",
    "    'Irrelevant': 2,\n",
    "    'Rant_Without_Visit': 3,\n",
    "}\n",
    "\n",
    "df['label'] = df['predicted_label'].map(tag_mapping_dict)\n",
    "\n",
    "\n",
    "# REPLACE this:\n",
    "# df[df['label']==None]\n",
    "# WITH:\n",
    "missing = df['label'].isna()\n",
    "print(\"Unmapped labels:\", int(missing.sum()))\n",
    "assert missing.sum() == 0, \"Found unmapped labels in predicted_label\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19ef9453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_name</th>\n",
       "      <th>text</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>prediction_reason</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>Lao Sze Chuan</td>\n",
       "      <td>Expect a lot of strange and interesting soundi...</td>\n",
       "      <td>Valid</td>\n",
       "      <td>The review provides a genuine dining experienc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Chinese restaurant']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>Walmart Supercenter</td>\n",
       "      <td>Corner Of Sullivan And Wax RD, Central, LA--Fo...</td>\n",
       "      <td>Valid</td>\n",
       "      <td>The review provides a genuine shopping experie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Department store', 'Clothing store', 'Craft ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            business_name                                               text  \\\n",
       "4600        Lao Sze Chuan  Expect a lot of strange and interesting soundi...   \n",
       "6089  Walmart Supercenter  Corner Of Sullivan And Wax RD, Central, LA--Fo...   \n",
       "\n",
       "     predicted_label                                  prediction_reason  \\\n",
       "4600           Valid  The review provides a genuine dining experienc...   \n",
       "6089           Valid  The review provides a genuine shopping experie...   \n",
       "\n",
       "     description                                           category  label  \n",
       "4600         NaN                             ['Chinese restaurant']      0  \n",
       "6089         NaN  ['Department store', 'Clothing store', 'Craft ...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ef419a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4600    {'business_name': 'Lao Sze Chuan', 'business_d...\n",
       "6089    {'business_name': 'Walmart Supercenter', 'busi...\n",
       "6988    {'business_name': 'China Harbor', 'business_de...\n",
       "1803    {'business_name': 'Zacatecas Restaurant', 'bus...\n",
       "3511    {'business_name': 'Saigon Noodles', 'business_...\n",
       "                              ...                        \n",
       "8442    {'business_name': 'Shamrock', 'business_descri...\n",
       "8446    {'business_name': 'Blue Lagoon Spa', 'business...\n",
       "8448    {'business_name': 'Sunrise Bakery Cafe', 'busi...\n",
       "8462    {'business_name': 'Key Village Shopping Center...\n",
       "8471    {'business_name': 'Pizza Palace Express', 'bus...\n",
       "Name: text, Length: 1087, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT_PREFIX=\"\"\"\n",
    "You are a top-tier content moderation expert specializing in the evaluation of Google Maps location reviews. \n",
    "Your task is to parse a JSON object containing review data and accurately classify it according to the following policies and rules.\n",
    "\"\"\"\n",
    "\n",
    "def create_json_from_row(row):\n",
    "    \"\"\"\n",
    "    Converts a DataFrame row into a JSON-formatted string.\n",
    "    \"\"\"\n",
    "    json_object = {\n",
    "        \"business_name\": row[\"business_name\"],\n",
    "        \"business_description\": row[\"description\"],\n",
    "        \"business_category\": row[\"category\"],\n",
    "        \"review_text\": row[\"text\"],\n",
    "        # \"review_length\": len(row[\"text\"]),\n",
    "    }\n",
    "    return str(json_object)\n",
    "    # return PROMPT_PREFIX+str(json_object)\n",
    "\n",
    "df['text'] = df.apply(create_json_from_row, axis=1)\n",
    "df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e098b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.loc[:, ['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23e31cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 869\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 218\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    df_filtered[['text','label']],\n",
    "    test_size=0.2,\n",
    "    random_state=seed,\n",
    "    stratify=df_filtered['label']\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_dataset   = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "\n",
    "my_dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "}).remove_columns([])  # nothing to drop now\n",
    "\n",
    "print(my_dataset_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810bd6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    96\n",
       "0    60\n",
       "1    35\n",
       "3    27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c5b29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu usage\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4,5,6,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927b6493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Device count: 7\n",
      "Current device: 0\n",
      "Device name: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available. Device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6215ea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 869/869 [00:00<00:00, 5417.97 examples/s]\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 7805.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "checkpoint = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "INSTRUCTION = (\n",
    "    \"Task: classify review for THIS business. \"\n",
    "    \"Labels: Valid, Advertisement, Irrelevant, Rant_Without_Visit. \"\n",
    "    \"Priority: Ad > Irrelevant > No-visit rant > Valid.\"\n",
    ")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    texts = example[\"text\"]\n",
    "    # texts is a list when batched=True; replicate the instruction to match length\n",
    "    instr = [INSTRUCTION] * len(texts)\n",
    "    return tokenizer(instr, texts, truncation=True, max_length=256)\n",
    "\n",
    "\n",
    "tokenized_datasets = my_dataset_dict.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# drop any raw columns that may exist (prompted_text OR text, and any index col)\n",
    "cols_to_drop = [c for c in tokenized_datasets[\"train\"].column_names \n",
    "                if c in [\"prompted_text\", \"text\", \"__index_level_0__\"]]\n",
    "if cols_to_drop:\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns(cols_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1300ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 99, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 1488, in forward\n    outputs = self.bert(\n              ^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n    encoder_outputs = self.encoder(\n                      ^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 653, in forward\n    layer_outputs = layer_module(\n                    ^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/modeling_layers.py\", line 94, in __call__\n    return super().__call__(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 562, in forward\n    self_attention_outputs = self.attention(\n                             ^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 493, in forward\n    self_outputs = self.self(\n                   ^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 385, in forward\n    self.key(current_states)\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 44.40 GiB of which 9.69 MiB is free. Process 2425686 has 36.51 GiB memory in use. Process 2915914 has 5.76 GiB memory in use. Including non-PyTorch memory, this process has 2.11 GiB memory in use. Of the allocated memory 1.45 GiB is allocated by PyTorch, and 52.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     41\u001b[39m trainer = Trainer(\n\u001b[32m     42\u001b[39m     model=model,                                   \u001b[38;5;66;03m# 模型会被自动移动到GPU\u001b[39;00m\n\u001b[32m     43\u001b[39m     args=training_args,                            \u001b[38;5;66;03m# 训练参数\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     compute_metrics=compute_metrics,               \u001b[38;5;66;03m# 增加评估指标\u001b[39;00m\n\u001b[32m     49\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# 4. 开始训练\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m#    在调用 .train() 时，每一批数据也会被自动发送到GPU\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/trainer.py:2238\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2236\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/trainer.py:2582\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2575\u001b[39m context = (\n\u001b[32m   2576\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2577\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2579\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2580\u001b[39m )\n\u001b[32m   2581\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2582\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2585\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2586\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2587\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2588\u001b[39m ):\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2590\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/trainer.py:3796\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3793\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3795\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3796\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3798\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3799\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3800\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3801\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3802\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/trainer.py:3884\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3882\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3883\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3885\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3886\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:194\u001b[39m, in \u001b[36mDataParallel.forward\u001b[39m\u001b[34m(self, *inputs, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module(*inputs[\u001b[32m0\u001b[39m], **module_kwargs[\u001b[32m0\u001b[39m])\n\u001b[32m    193\u001b[39m replicas = \u001b[38;5;28mself\u001b[39m.replicate(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.device_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gather(outputs, \u001b[38;5;28mself\u001b[39m.output_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:213\u001b[39m, in \u001b[36mDataParallel.parallel_apply\u001b[39m\u001b[34m(self, replicas, inputs, kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparallel_apply\u001b[39m(\n\u001b[32m    211\u001b[39m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[32m    212\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Any]:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:129\u001b[39m, in \u001b[36mparallel_apply\u001b[39m\u001b[34m(modules, inputs, kwargs_tup, devices)\u001b[39m\n\u001b[32m    127\u001b[39m     output = results[i]\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m         \u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m     outputs.append(output)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/_utils.py:769\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    766\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    767\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py\", line 99, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 1488, in forward\n    outputs = self.bert(\n              ^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n    encoder_outputs = self.encoder(\n                      ^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 653, in forward\n    layer_outputs = layer_module(\n                    ^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/modeling_layers.py\", line 94, in __call__\n    return super().__call__(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 562, in forward\n    self_attention_outputs = self.attention(\n                             ^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 493, in forward\n    self_outputs = self.self(\n                   ^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py\", line 385, in forward\n    self.key(current_states)\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 44.40 GiB of which 9.69 MiB is free. Process 2425686 has 36.51 GiB memory in use. Process 2915914 has 5.76 GiB memory in use. Including non-PyTorch memory, this process has 2.11 GiB memory in use. Of the allocated memory 1.45 GiB is allocated by PyTorch, and 52.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=4,ignore_mismatched_sizes=True)\n",
    "\n",
    "# 简单评估指标（最小改动）\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\", zero_division=0),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n",
    "    }\n",
    "\n",
    "# 2. 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{checkpoint}\",\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    # Add these two lines to show training loss\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=6,  \n",
    "    fp16=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# 假设你已经准备好了 tokenized_datasets\n",
    "# tokenized_datasets['train'], tokenized_datasets['test']\n",
    "\n",
    "# 3. 初始化 Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                                   # 模型会被自动移动到GPU\n",
    "    args=training_args,                            # 训练参数\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,                           # （替换 processing_class）\n",
    "    compute_metrics=compute_metrics,               # 增加评估指标\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f79687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             Valid      0.806     0.833     0.820        60\n",
      "     Advertisement      0.943     0.943     0.943        35\n",
      "        Irrelevant      0.914     0.885     0.899        96\n",
      "Rant_Without_Visit      0.929     0.963     0.945        27\n",
      "\n",
      "          accuracy                          0.890       218\n",
      "         macro avg      0.898     0.906     0.902       218\n",
      "      weighted avg      0.891     0.890     0.890       218\n",
      "\n",
      "Confusion matrix:\n",
      " [[50  1  7  2]\n",
      " [ 1 33  1  0]\n",
      " [11  0 85  0]\n",
      " [ 0  1  0 26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "id2label = {0: \"Valid\", 1: \"Advertisement\", 2: \"Irrelevant\", 3: \"Rant_Without_Visit\"}\n",
    "all_labels = [0, 1, 2, 3]\n",
    "target_names = [id2label[i] for i in all_labels]\n",
    "\n",
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "preds = np.argmax(logits, axis=-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d5c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一阶段预测为 'label=0' 的数据有 62 条。\n",
      "已成功创建用于第二阶段预测的新数据集：\n",
      "Dataset({\n",
      "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 62\n",
      "})\n",
      "正在将数据集保存到 './stage2_filtered_data' ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 62/62 [00:00<00:00, 15490.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "preds = np.argmax(logits, axis=-1).astype(int)\n",
    "\n",
    "mask = (preds == 0)\n",
    "indices_to_stage2 = np.where(mask)[0]\n",
    "stage2_dataset = tokenized_datasets[\"validation\"].select(indices_to_stage2)\n",
    "print(stage2_dataset)\n",
    "stage2_labels = labels[mask]\n",
    "save_path = \"./stage2_filtered_data\"\n",
    "stage2_dataset.save_to_disk(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "load_path = \"./stage2_filtered_data\"\n",
    "loaded_stage2_dataset = load_from_disk(load_path)\n",
    "print(loaded_stage2_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae1401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangguibin/anaconda3/envs/dra_ykm/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             Valid      0.806     0.833     0.820        60\n",
      "     Advertisement      0.943     0.943     0.943        35\n",
      "        Irrelevant      0.914     0.885     0.899        96\n",
      "Rant_Without_Visit      0.929     0.963     0.945        27\n",
      "\n",
      "          accuracy                          0.890       218\n",
      "         macro avg      0.898     0.906     0.902       218\n",
      "      weighted avg      0.891     0.890     0.890       218\n",
      "\n",
      "Confusion matrix:\n",
      " [[50  1  7  2]\n",
      " [ 1 33  1  0]\n",
      " [11  0 85  0]\n",
      " [ 0  1  0 26]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "id2label = {0: \"Valid\", 1: \"Advertisement\", 2: \"Irrelevant\", 3: \"Rant_Without_Visit\"}\n",
    "all_labels = [0, 1, 2, 3]\n",
    "target_names = [id2label[i] for i in all_labels]\n",
    "# stage2_predictions = trainer_stage2.predict(loaded_stage2_dataset)\n",
    "predictions = trainer.predict(loaded_stage2_dataset)\n",
    "logits = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "preds = np.argmax(logits, axis=-1).astype(int)\n",
    "\n",
    "\n",
    "print(classification_report(\n",
    "    labels, preds,\n",
    "    labels=all_labels,              # <-- ensure fixed label set\n",
    "    target_names=target_names,\n",
    "    zero_division=0,\n",
    "    digits=3\n",
    "))\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(labels, preds, labels=all_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dra_ykm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
